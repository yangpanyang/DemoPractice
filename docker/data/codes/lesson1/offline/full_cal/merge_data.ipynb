{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/opt/codes/lesson1\n"
     ]
    }
   ],
   "source": [
    "%config ZMQInteractiveShell.ast_node_interactivity='all'\n",
    "import os\n",
    "import sys\n",
    "\n",
    "BASE_DIR = \"/opt/codes/lesson1\"\n",
    "sys.path.insert(0, os.path.join(BASE_DIR))\n",
    "print(BASE_DIR)\n",
    "\n",
    "PYSPARK_PYTHON = \"/usr/bin/python3.6\"\n",
    "os.environ[\"PYSPARK_PYTHON\"] = PYSPARK_PYTHON\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = PYSPARK_PYTHON\n",
    "os.environ[\"JAVA_HOME\"] = '/usr/lib/jvm/java-8-openjdk-amd64'\n",
    "from offline import SparkSessionBase  # import init文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OriginArticleData(SparkSessionBase):\n",
    "    \n",
    "    SPARK_APP_NAME = \"Lesson1\"\n",
    "    # SPARK_URL = \"yarn\"\n",
    "\n",
    "    ENABLE_HIVE_SUPPORT = True\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.spark = self._create_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True (('spark.app.name', 'Lesson1'), ('spark.executor.memory', '8g'), ('spark.executor.cores', 8), ('spark.executor.instances', 8), ('hive.metastore.uris', 'thrift://172.18.0.2:9083'))\n"
     ]
    }
   ],
   "source": [
    "oa = OriginArticleData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# 读取文章，进行每篇张分词\n",
    "oa.spark.sql(\"use article\")\n",
    "article_data = oa.spark.sql(\"select * from article_data\")\n",
    "# article_data.count()\n",
    "# article_data.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文章数据进行分词处理,得到分词结果\n",
    "# 分词\n",
    "def segmentation(partition):\n",
    "    import os\n",
    "    import re\n",
    "\n",
    "    import jieba\n",
    "    import jieba.analyse\n",
    "    import jieba.posseg as pseg\n",
    "    import codecs\n",
    "\n",
    "    abspath = \"/opt/words/\"\n",
    "\n",
    "    # 结巴加载用户词典\n",
    "    userDict_path = os.path.join(abspath, \"ITKeywords.txt\")\n",
    "    jieba.load_userdict(userDict_path)\n",
    "\n",
    "    # 停用词文本\n",
    "    stopwords_path = os.path.join(abspath, \"stopwords.txt\")\n",
    "\n",
    "    def get_stopwords_list():\n",
    "        \"\"\"返回stopwords列表\"\"\"\n",
    "        stopwords_list = [i.strip()\n",
    "                          for i in codecs.open(stopwords_path, encoding='utf-8').readlines()]\n",
    "        return stopwords_list\n",
    "\n",
    "    # 所有的停用词列表\n",
    "    stopwords_list = get_stopwords_list()\n",
    "\n",
    "    # 分词\n",
    "    def cut_sentence(sentence):\n",
    "        \"\"\"对切割之后的词语进行过滤，去除停用词，保留名词，英文和自定义词库中的词，长度大于2的词\"\"\"\n",
    "        # print(sentence,\"*\"*100)\n",
    "        # eg:[pair('今天', 't'), pair('有', 'd'), pair('雾', 'n'), pair('霾', 'g')]\n",
    "        seg_list = pseg.lcut(sentence)\n",
    "        seg_list = [i for i in seg_list if i.flag not in stopwords_list]\n",
    "        filtered_words_list = []\n",
    "        for seg in seg_list:\n",
    "            # print(seg)\n",
    "            if len(seg.word) <= 1:\n",
    "                continue\n",
    "            elif seg.flag == \"eng\":\n",
    "                if len(seg.word) <= 2:\n",
    "                    continue\n",
    "                else:\n",
    "                    filtered_words_list.append(seg.word)\n",
    "            elif seg.flag.startswith(\"n\"):\n",
    "                filtered_words_list.append(seg.word)\n",
    "            elif seg.flag in [\"x\", \"eng\"]:  # 是自定一个词语或者是英文单词\n",
    "                filtered_words_list.append(seg.word)\n",
    "        return filtered_words_list\n",
    "\n",
    "    for row in partition:\n",
    "        sentence = re.sub(\"<.*?>\", \"\", row.sentence)    # 替换掉标签数据\n",
    "        words = cut_sentence(sentence)\n",
    "        yield row.article_id, row.channel_id, words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = article_data.rdd.mapPartitions(segmentation).toDF(['article_id', 'channel_id', 'words'])\n",
    "# words_df.count()\n",
    "# words_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Row(article_id=1, channel_id=17, words=['Vue', 'props', '用法', '小结', 'Vue', 'props', '用法', '组件', '选项', 'props', 'Vue', '选项', '父子', '组件', '关系', '总结', 'props', 'down', 'events', '组件', 'props', '传递数据', '组件', '组件', 'events', '组件', '发送消息', '父子', '组件', '组件', 'pa', 'rent', 'child', '组件', '环境', '书写', '组件', '可维护性', '定义', '父子', '组件', 'Vue', '对象', 'var', 'childNode', 'template', 'div', 'childNode', 'div', 'var', 'pa', 'rentNode', 'template', 'div', 'child', 'child', 'child', 'child', 'div', 'components', 'child', 'childNode', '全栈', '交流', 'Ian', '人员', '技术', '瓶颈', '思维能力', 'new', 'Vue', 'example', 'components', 'pa', 'rent', 'pa', 'rentNode', 'div', 'example', 'pa', 'rent', 'pa', 'rent', 'div', 'childNode', '定义', 'template', 'div', '内容', 'childNode', '字符串', 'pa', 'rentNode', 'template', '定义', 'div', 'class', 'pa', 'rent', 'child', '组件', '静态', 'props', '组件', '实例', '作用域', '组件', '模板', '饮用', '组件', '数据', '组件', '组件', '数据', '组件', 'props', '选项', '组件', '向子', '组件', '传递数据', '方式', '动态', '静态', '静态', '方式', '组件', 'props', '声明', '数据', '上例', '代码', 'childNode', 'props', '选项', 'forChildMsg', '数据', '组件', '占位符', '特性', '方式', '传递数据', 'var', 'childNode', 'template', 'div', 'forChildMsg', 'div', 'props', 'for', 'child', 'msg', 'var', 'pa', 'rentNode', 'template', 'div', 'pa', 'rentNode', 'child', 'for', 'child', 'msg', 'aaa', 'child', 'child', 'for', 'child', 'msg', 'bbb', 'child', 'div', 'components', 'child', 'childNode', '命名规范', 'props', '声明', '属性', '组件', 'template', '模板', '属性', '中划线', '组件', 'props', '属性', '声明', '驼峰', '中划线', '组件', '模板', '组件', '驼峰', 'Vue', '驼峰', '命名', 'forChildMsg', 'for', 'child', 'msg', '动态', 'props', '模板', '动态', '组件', '数据', '组件', '模板', 'props', 'Html', '标签', '特性', 'bind', '静态', 'props', '代码', '组件', 'var', 'pa', 'rentNode', 'template', 'div', 'pa', 'rentNode', 'child', 'for', 'child', 'msg', 'childMsg1', 'child', 'child', 'for', 'child', 'msg', 'childMsg2', 'child', 'div', 'components', 'child', 'childNode', 'data', 'function', 'return', 'childMsg1', 'Dynamic', 'props', 'msg', 'for', 'child', 'childMsg2', 'Dynamic', 'props', 'msg', 'for', 'child', '组件', 'data', 'return', '数据', 'childMsg1', 'childMsg2', '组件', 'props', 'props', '参数', '数据', '规格', '数据', '规格', 'Vue', '警告', '种类', 'type', 'String', 'Number', 'Boolean', 'Function', 'Object', 'Array', 'SymbolVue', 'component', 'example', 'props', '基础', '类型', 'ul', '类型', '都行', 'propA', 'Number', '多种类型', 'propB', 'String', 'Number', 'String', 'propC', 'type', 'String', 'required', 'true', '数字', 'propD', 'type', 'Number', 'defa', 'ul', '数组', '工厂', '函数返回', '对象', 'propE', 'type', 'Object', 'defa', 'ul', 'function', 'console', 'log', 'propE', 'defa', 'ul', 'invoked', 'return', 'message', 'from', 'propE', '函数', 'propF', 'isValid', 'function', 'value', 'return', 'value', 'let', 'childNode', 'template', 'div', 'forChildMsg', 'div', 'props', 'for', 'child', 'msg', 'Number', 'let', 'pa', 'rentNode', 'template', 'div', 'class', 'pa', 'rent', 'child', 'for', 'child', 'msg', 'msg', 'child', 'div', 'components', 'child', 'childNode', 'data', 'return', '字符串', '时会', 'msg', 'props', '定义', '数据', '函数', '函数返回', 'false', '警告', '例子', 'childNode', 'for', 'child', 'msg', '一个对象', 'validator', '函数', '命名', '规定', 'validator', '自定义函数', '生效', 'let', 'childNode', 'template', 'div', 'forChildMsg', 'div', 'props', 'for', 'child', 'msg', 'validator', 'function', 'value', 'return', 'value', 'for', 'child', 'msg', 'validator', '函数', '警告', '单向', '数据流', 'props', '单向', '组件', '属性', '传导', '组件', '组件', '组件', '状态', '组件', 'props', 'Vue', '警告', 'let', 'childNode', 'template', 'div', 'class', 'child', 'div', 'pa', '组件', '数据', 'pa', 'input', 'model', 'forChildMsg', 'div', 'forChildMsg', 'div', 'props', 'for', 'child', 'msg', 'String', 'let', 'pa', 'rentNode', 'template', 'div', 'class', 'pa', 'rent', 'div', 'pa', '组件', '数据', 'pa', 'input', 'model', 'msg', 'div', 'msg', 'child', 'for', 'child', 'msg', 'msg', 'child', 'div', 'components', 'child', 'childNode', 'data', 'return', 'msg', 'defa', 'ul', 'string', '组件', '和子', '组件', '输入框', '组件', '数据', '和子', '组件', '数据', '组件', '输入框', '数据', '组件', '数据', 'props', '向子', '组件', '传递数据', '组件', '输入框', '浏览器', '错误', '警告', 'Vue', 'warn', 'Avoid', 'mutating', 'prop', 'directly', 'since', 'the', 'value', 'will', 'overwritten', 'whenever', 'the', 'pa', 'rent', 'component', 'renders', 'Instead', 'use', 'data', 'computed', 'property', 'based', 'the', 'prop', 'value', 'Prop', 'being', 'mutated', 'forChildMsg', 'props', '数据', '原因', 'prop', '组件', '局部', '数据', 'prop', '由子', '组件', '数据', '办法', '定义', '局部变量', 'prop', '定义', 'ownChildMsg', 'forChildMsg', '组件', 'ownChildMsg', '无法', 'childNode', 'template', 'div', 'class', 'child', 'div', 'pa', '组件', '数据', 'pa', 'input', 'model', 'forChildMsg', 'div', 'forChildMsg', 'ownChildMsg', 'ownChildMsg', 'div', 'props', 'for', 'child', 'msg', 'String', 'data', 'return', 'ownChildMsg', 'this', 'forChildMsg', 'ownChildMsg', '数据', '结果', 'ownChildMsg', '组件', 'forChildMsg', 'ownChildMsg', '定义', '属性', 'prop', '属性', '组件', 'forChildMsg', '数据', 'forChildMsg', '字符串', 'ownChildMsg', '屏幕', '组件', '数据', 'ownChildMsg', '数据', 'let', 'childNode', 'template', 'div', 'class', 'child', 'div', 'pa', '组件', '数据', 'pa', 'input', 'model', 'forChildMsg', 'div', 'forChildMsg', 'ownChildMsg', 'ownChildMsg', 'div', 'props', 'for', 'child', 'msg', 'String', 'computed', 'ownChildMsg', 'return', 'this', 'forChildMsg', 'ownChildMsg', '方式', 'prop', 'watch', 'prop', 'let', 'childNode', 'template', 'div', 'class', 'child', 'div', 'pa', '组件', '数据', 'pa', 'input', 'model', 'forChildMsg', 'div', 'forChildMsg', 'ownChildMsg', 'ownChildMsg', 'div', 'props', 'for', 'child', 'msg', 'String', 'data', 'return', 'ownChildMsg', 'this', 'forChildMsg', '全栈', '交流', '人员', '技术', '瓶颈', '思维能力', 'watch', 'forChildMsg', 'this', 'ownChildMsg', 'this', 'forChildMsg'])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先计算分词之后的每篇文章的词频，得到CV模型\n",
    "# 统计所有文章不同的词，组成一个词列表 words_list = [1,2,3,,34,4,45,56,67,78,8.......,,,,.]\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "cv = CountVectorizer(inputCol='words', outputCol='countFeatures', vocabSize=1000, minDF=5)\n",
    "cv_model = cv.fit(words_df)\n",
    "\n",
    "# 然后根据词频计算IDF以及词，得到IDF模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_model.write().overwrite().save(\"hdfs://hadoop-master:9000/headlines/models/test.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizerModel\n",
    "cv_m = CountVectorizerModel.load(\"hdfs://hadoop-master:9000/headlines/models/test.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result = cv_m.transform(words_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result.show()\n",
    "cv_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDF 模型\n",
    "from pyspark.ml.feature import IDF\n",
    "idf = IDF(inputCol=\"countFeatures\", outputCol=\"idfFeatures\")\n",
    "idfModel = idf.fit(cv_result)\n",
    "idfModel.write().overwrite().save(\"hdfs://hadoop-master:9000/headlines/models/testIDF.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDF对CV结果进行计算TFIDF\n",
    "from pyspark.ml.feature import IDFModel\n",
    "idf_model = IDFModel.load(\"hdfs://hadoop-master:9000/headlines/models/testIDF.model\")\n",
    "tfidf_res = idf_model.transform(cv_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+----------+---------------------------+--------------------+--------------------+\n|article_id|channel_id|                      words|       countFeatures|         idfFeatures|\n+----------+----------+---------------------------+--------------------+--------------------+\n|         1|        17|     [Vue, props, 用法, ...|(1266,[0,1,3,4,5,...|(1266,[0,1,3,4,5,...|\n|         2|        17|  [vue, 响应式, 原理, mo...|(1266,[0,1,2,3,4,...|(1266,[0,1,2,3,4,...|\n|         3|        17|    [JavaScript, 浅拷贝,...|(1266,[0,1,5,7,12...|(1266,[0,1,5,7,12...|\n|         4|        17|       [vue2, vuex, elem...|(1266,[1,2,4,9,12...|(1266,[1,2,4,9,12...|\n|         5|        17|       [immutability, Re...|(1266,[1,3,4,5,6,...|(1266,[1,3,4,5,6,...|\n|         6|        17|       [node, npm, cnpm,...|(1266,[1,2,9,12,1...|(1266,[1,2,9,12,1...|\n|         7|        17|[Web, 工程师, 以太坊, 入...|(1266,[1,2,3,4,6,...|(1266,[1,2,3,4,6,...|\n|         8|        17|       [Web, pa, api, we...|(1266,[1,2,9,30,3...|(1266,[1,2,9,30,3...|\n|         9|        17|[vue, 中用, 数据驱动, 视...|(1266,[0,1,4,8,14...|(1266,[0,1,4,8,14...|\n|        10|        17|    [程序, WebSocket, 长...|(1266,[0,1,3,8,12...|(1266,[0,1,3,8,12...|\n+----------+----------+---------------------------+--------------------+--------------------+\n\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Row(article_id=1, channel_id=17, words=['Vue', 'props', '用法', '小结', 'Vue', 'props', '用法', '组件', '选项', 'props', 'Vue', '选项', '父子', '组件', '关系', '总结', 'props', 'down', 'events', '组件', 'props', '传递数据', '组件', '组件', 'events', '组件', '发送消息', '父子', '组件', '组件', 'pa', 'rent', 'child', '组件', '环境', '书写', '组件', '可维护性', '定义', '父子', '组件', 'Vue', '对象', 'var', 'childNode', 'template', 'div', 'childNode', 'div', 'var', 'pa', 'rentNode', 'template', 'div', 'child', 'child', 'child', 'child', 'div', 'components', 'child', 'childNode', '全栈', '交流', 'Ian', '人员', '技术', '瓶颈', '思维能力', 'new', 'Vue', 'example', 'components', 'pa', 'rent', 'pa', 'rentNode', 'div', 'example', 'pa', 'rent', 'pa', 'rent', 'div', 'childNode', '定义', 'template', 'div', '内容', 'childNode', '字符串', 'pa', 'rentNode', 'template', '定义', 'div', 'class', 'pa', 'rent', 'child', '组件', '静态', 'props', '组件', '实例', '作用域', '组件', '模板', '饮用', '组件', '数据', '组件', '组件', '数据', '组件', 'props', '选项', '组件', '向子', '组件', '传递数据', '方式', '动态', '静态', '静态', '方式', '组件', 'props', '声明', '数据', '上例', '代码', 'childNode', 'props', '选项', 'forChildMsg', '数据', '组件', '占位符', '特性', '方式', '传递数据', 'var', 'childNode', 'template', 'div', 'forChildMsg', 'div', 'props', 'for', 'child', 'msg', 'var', 'pa', 'rentNode', 'template', 'div', 'pa', 'rentNode', 'child', 'for', 'child', 'msg', 'aaa', 'child', 'child', 'for', 'child', 'msg', 'bbb', 'child', 'div', 'components', 'child', 'childNode', '命名规范', 'props', '声明', '属性', '组件', 'template', '模板', '属性', '中划线', '组件', 'props', '属性', '声明', '驼峰', '中划线', '组件', '模板', '组件', '驼峰', 'Vue', '驼峰', '命名', 'forChildMsg', 'for', 'child', 'msg', '动态', 'props', '模板', '动态', '组件', '数据', '组件', '模板', 'props', 'Html', '标签', '特性', 'bind', '静态', 'props', '代码', '组件', 'var', 'pa', 'rentNode', 'template', 'div', 'pa', 'rentNode', 'child', 'for', 'child', 'msg', 'childMsg1', 'child', 'child', 'for', 'child', 'msg', 'childMsg2', 'child', 'div', 'components', 'child', 'childNode', 'data', 'function', 'return', 'childMsg1', 'Dynamic', 'props', 'msg', 'for', 'child', 'childMsg2', 'Dynamic', 'props', 'msg', 'for', 'child', '组件', 'data', 'return', '数据', 'childMsg1', 'childMsg2', '组件', 'props', 'props', '参数', '数据', '规格', '数据', '规格', 'Vue', '警告', '种类', 'type', 'String', 'Number', 'Boolean', 'Function', 'Object', 'Array', 'SymbolVue', 'component', 'example', 'props', '基础', '类型', 'ul', '类型', '都行', 'propA', 'Number', '多种类型', 'propB', 'String', 'Number', 'String', 'propC', 'type', 'String', 'required', 'true', '数字', 'propD', 'type', 'Number', 'defa', 'ul', '数组', '工厂', '函数返回', '对象', 'propE', 'type', 'Object', 'defa', 'ul', 'function', 'console', 'log', 'propE', 'defa', 'ul', 'invoked', 'return', 'message', 'from', 'propE', '函数', 'propF', 'isValid', 'function', 'value', 'return', 'value', 'let', 'childNode', 'template', 'div', 'forChildMsg', 'div', 'props', 'for', 'child', 'msg', 'Number', 'let', 'pa', 'rentNode', 'template', 'div', 'class', 'pa', 'rent', 'child', 'for', 'child', 'msg', 'msg', 'child', 'div', 'components', 'child', 'childNode', 'data', 'return', '字符串', '时会', 'msg', 'props', '定义', '数据', '函数', '函数返回', 'false', '警告', '例子', 'childNode', 'for', 'child', 'msg', '一个对象', 'validator', '函数', '命名', '规定', 'validator', '自定义函数', '生效', 'let', 'childNode', 'template', 'div', 'forChildMsg', 'div', 'props', 'for', 'child', 'msg', 'validator', 'function', 'value', 'return', 'value', 'for', 'child', 'msg', 'validator', '函数', '警告', '单向', '数据流', 'props', '单向', '组件', '属性', '传导', '组件', '组件', '组件', '状态', '组件', 'props', 'Vue', '警告', 'let', 'childNode', 'template', 'div', 'class', 'child', 'div', 'pa', '组件', '数据', 'pa', 'input', 'model', 'forChildMsg', 'div', 'forChildMsg', 'div', 'props', 'for', 'child', 'msg', 'String', 'let', 'pa', 'rentNode', 'template', 'div', 'class', 'pa', 'rent', 'div', 'pa', '组件', '数据', 'pa', 'input', 'model', 'msg', 'div', 'msg', 'child', 'for', 'child', 'msg', 'msg', 'child', 'div', 'components', 'child', 'childNode', 'data', 'return', 'msg', 'defa', 'ul', 'string', '组件', '和子', '组件', '输入框', '组件', '数据', '和子', '组件', '数据', '组件', '输入框', '数据', '组件', '数据', 'props', '向子', '组件', '传递数据', '组件', '输入框', '浏览器', '错误', '警告', 'Vue', 'warn', 'Avoid', 'mutating', 'prop', 'directly', 'since', 'the', 'value', 'will', 'overwritten', 'whenever', 'the', 'pa', 'rent', 'component', 'renders', 'Instead', 'use', 'data', 'computed', 'property', 'based', 'the', 'prop', 'value', 'Prop', 'being', 'mutated', 'forChildMsg', 'props', '数据', '原因', 'prop', '组件', '局部', '数据', 'prop', '由子', '组件', '数据', '办法', '定义', '局部变量', 'prop', '定义', 'ownChildMsg', 'forChildMsg', '组件', 'ownChildMsg', '无法', 'childNode', 'template', 'div', 'class', 'child', 'div', 'pa', '组件', '数据', 'pa', 'input', 'model', 'forChildMsg', 'div', 'forChildMsg', 'ownChildMsg', 'ownChildMsg', 'div', 'props', 'for', 'child', 'msg', 'String', 'data', 'return', 'ownChildMsg', 'this', 'forChildMsg', 'ownChildMsg', '数据', '结果', 'ownChildMsg', '组件', 'forChildMsg', 'ownChildMsg', '定义', '属性', 'prop', '属性', '组件', 'forChildMsg', '数据', 'forChildMsg', '字符串', 'ownChildMsg', '屏幕', '组件', '数据', 'ownChildMsg', '数据', 'let', 'childNode', 'template', 'div', 'class', 'child', 'div', 'pa', '组件', '数据', 'pa', 'input', 'model', 'forChildMsg', 'div', 'forChildMsg', 'ownChildMsg', 'ownChildMsg', 'div', 'props', 'for', 'child', 'msg', 'String', 'computed', 'ownChildMsg', 'return', 'this', 'forChildMsg', 'ownChildMsg', '方式', 'prop', 'watch', 'prop', 'let', 'childNode', 'template', 'div', 'class', 'child', 'div', 'pa', '组件', '数据', 'pa', 'input', 'model', 'forChildMsg', 'div', 'forChildMsg', 'ownChildMsg', 'ownChildMsg', 'div', 'props', 'for', 'child', 'msg', 'String', 'data', 'return', 'ownChildMsg', 'this', 'forChildMsg', '全栈', '交流', '人员', '技术', '瓶颈', '思维能力', 'watch', 'forChildMsg', 'this', 'ownChildMsg', 'this', 'forChildMsg'], countFeatures=SparseVector(1266, {0: 5.0, 1: 27.0, 3: 7.0, 4: 25.0, 5: 7.0, 8: 55.0, 10: 45.0, 12: 1.0, 13: 6.0, 15: 1.0, 16: 6.0, 17: 5.0, 18: 10.0, 19: 40.0, 26: 31.0, 27: 24.0, 29: 2.0, 30: 2.0, 31: 5.0, 33: 18.0, 35: 5.0, 39: 23.0, 42: 7.0, 44: 4.0, 47: 1.0, 49: 1.0, 55: 18.0, 58: 18.0, 61: 1.0, 62: 4.0, 66: 16.0, 74: 2.0, 77: 5.0, 81: 1.0, 82: 4.0, 90: 7.0, 102: 2.0, 106: 3.0, 118: 3.0, 125: 2.0, 128: 1.0, 138: 9.0, 139: 9.0, 144: 2.0, 150: 8.0, 153: 1.0, 171: 8.0, 172: 1.0, 173: 1.0, 175: 8.0, 197: 1.0, 206: 6.0, 208: 1.0, 210: 5.0, 230: 2.0, 239: 5.0, 242: 1.0, 263: 2.0, 267: 5.0, 269: 2.0, 274: 3.0, 294: 4.0, 301: 4.0, 310: 2.0, 312: 1.0, 315: 3.0, 318: 2.0, 328: 4.0, 330: 4.0, 333: 4.0, 342: 1.0, 346: 4.0, 350: 2.0, 370: 1.0, 381: 3.0, 382: 3.0, 390: 3.0, 395: 1.0, 397: 3.0, 399: 1.0, 402: 1.0, 410: 3.0, 415: 1.0, 427: 3.0, 458: 2.0, 462: 1.0, 465: 1.0, 466: 3.0, 471: 1.0, 476: 1.0, 484: 2.0, 485: 2.0, 487: 2.0, 489: 1.0, 497: 2.0, 508: 2.0, 513: 2.0, 524: 1.0, 529: 1.0, 547: 1.0, 558: 2.0, 562: 1.0, 567: 2.0, 574: 1.0, 580: 1.0, 594: 2.0, 601: 1.0, 608: 2.0, 630: 1.0, 634: 2.0, 658: 1.0, 662: 1.0, 669: 1.0, 674: 1.0, 692: 1.0, 697: 1.0, 710: 1.0, 752: 1.0, 753: 1.0, 757: 1.0, 764: 1.0, 804: 1.0, 811: 1.0, 835: 1.0, 840: 1.0, 841: 1.0, 867: 1.0, 871: 1.0, 873: 1.0, 878: 1.0, 885: 1.0, 890: 1.0, 892: 1.0, 896: 1.0, 910: 1.0, 914: 1.0, 915: 1.0, 924: 1.0, 937: 1.0, 948: 1.0, 955: 1.0, 984: 1.0, 997: 1.0, 1001: 1.0, 1032: 1.0, 1103: 1.0, 1132: 1.0, 1135: 1.0, 1148: 1.0, 1168: 1.0, 1176: 1.0, 1177: 1.0, 1183: 1.0, 1187: 1.0, 1205: 1.0, 1206: 1.0, 1208: 1.0, 1219: 1.0, 1224: 1.0, 1256: 1.0, 1265: 1.0}), idfFeatures=SparseVector(1266, {0: 3.0307, 1: 0.0, 3: 4.243, 4: 11.2996, 5: 5.5192, 8: 55.6381, 10: 58.4677, 12: 0.3185, 13: 6.0696, 15: 0.452, 16: 4.7307, 17: 3.9423, 18: 4.5199, 19: 68.1899, 26: 52.8472, 27: 31.1828, 29: 0.4013, 30: 0.6369, 31: 1.0034, 33: 8.1357, 35: 6.4964, 39: 39.2092, 42: 5.5192, 44: 2.4245, 47: 0.7885, 49: 0.6061, 55: 30.6855, 58: 30.6855, 61: 0.7885, 62: 2.4245, 66: 27.276, 74: 1.5769, 77: 6.4964, 81: 0.7885, 82: 1.8079, 90: 5.5192, 102: 1.2123, 106: 3.0348, 118: 2.3654, 125: 2.5986, 128: 0.6061, 138: 15.3427, 139: 15.3427, 144: 1.5769, 150: 13.638, 153: 0.452, 171: 13.638, 172: 1.2993, 173: 0.452, 175: 13.638, 197: 1.0116, 206: 10.2285, 208: 0.7885, 210: 6.4964, 230: 1.5769, 239: 8.5237, 242: 0.7885, 263: 2.0232, 267: 8.5237, 269: 2.0232, 274: 3.8978, 294: 6.819, 301: 6.819, 310: 2.5986, 312: 1.0116, 315: 3.8978, 318: 2.5986, 328: 6.819, 330: 6.819, 333: 6.819, 342: 1.2993, 346: 6.819, 350: 2.5986, 370: 1.0116, 381: 5.1142, 382: 5.1142, 390: 5.1142, 395: 1.2993, 397: 5.1142, 399: 1.0116, 402: 1.0116, 410: 5.1142, 415: 1.2993, 427: 5.1142, 458: 2.5986, 462: 1.0116, 465: 1.2993, 466: 5.1142, 471: 1.0116, 476: 1.0116, 484: 3.4095, 485: 3.4095, 487: 3.4095, 489: 1.2993, 497: 3.4095, 508: 3.4095, 513: 3.4095, 524: 1.2993, 529: 1.2993, 547: 1.2993, 558: 3.4095, 562: 1.2993, 567: 3.4095, 574: 1.2993, 580: 1.2993, 594: 3.4095, 601: 1.2993, 608: 3.4095, 630: 1.2993, 634: 3.4095, 658: 1.7047, 662: 1.7047, 669: 1.7047, 674: 1.7047, 692: 1.7047, 697: 1.7047, 710: 1.7047, 752: 1.7047, 753: 1.7047, 757: 1.7047, 764: 1.7047, 804: 1.7047, 811: 1.7047, 835: 1.7047, 840: 1.7047, 841: 1.7047, 867: 1.7047, 871: 1.7047, 873: 1.7047, 878: 1.7047, 885: 1.7047, 890: 1.7047, 892: 1.7047, 896: 1.7047, 910: 1.7047, 914: 1.7047, 915: 1.7047, 924: 1.7047, 937: 1.7047, 948: 1.7047, 955: 1.7047, 984: 1.7047, 997: 1.7047, 1001: 1.7047, 1032: 1.7047, 1103: 1.7047, 1132: 1.7047, 1135: 1.7047, 1148: 1.7047, 1168: 1.7047, 1176: 1.7047, 1177: 1.7047, 1183: 1.7047, 1187: 1.7047, 1205: 1.7047, 1206: 1.7047, 1208: 1.7047, 1219: 1.7047, 1224: 1.7047, 1256: 1.7047, 1265: 1.7047}))"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "tfidf_res.show()\n",
    "tfidf_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = tfidf_res.head(1)[0]\n",
    "row.idfFeatures\n",
    "_ = list(zip(row.idfFeatures.indices, row.idfFeatures.values))\n",
    "_ = sorted(_, key=lambda x: x[1], reverse=True)\n",
    "_\n",
    "result = _[:20]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1265词的 {索引 以及 权重}\n",
    "def func(partition):\n",
    "    TOPK = 20\n",
    "    # 找到索引与IDF值并进行排序\n",
    "    for row in partition:\n",
    "        # 一行有很多个词，所以要用zip展开，分别拿到\"索引-权重\"的tuple值\n",
    "        _ = list(zip(row.idfFeatures.indices, row.idfFeatures.values))\n",
    "        _ = sorted(_, key=lambda x: x[1], reverse=True)\n",
    "        result = _[:TOPK]  # 一行返回TOPK个重要的词\n",
    "        for word_index, tfidf in result:  # 重新拼接值返回，对于当前行row的article_id、channel_id是一样的\n",
    "            yield row.article_id, row.channel_id, int(word_index), round(float(tfidf), 4)\n",
    "kewords_tfidf = tfidf_res.rdd.mapPartitions(func).toDF(['article_id', 'channel_id', 'index', 'weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "metadata": {},
     "execution_count": 19
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+----------+-----+-------+\n|article_id|channel_id|index|weights|\n+----------+----------+-----+-------+\n|         1|        17|   19|68.1899|\n|         1|        17|   10|58.4677|\n|         1|        17|    8|55.6381|\n|         1|        17|   26|52.8472|\n|         1|        17|   39|39.2092|\n|         1|        17|   27|31.1828|\n|         1|        17|   55|30.6855|\n|         1|        17|   58|30.6855|\n|         1|        17|   66| 27.276|\n|         1|        17|  138|15.3427|\n|         1|        17|  139|15.3427|\n|         1|        17|  150| 13.638|\n|         1|        17|  171| 13.638|\n|         1|        17|  175| 13.638|\n|         1|        17|    4|11.2996|\n|         1|        17|  206|10.2285|\n|         1|        17|  239| 8.5237|\n|         1|        17|  267| 8.5237|\n|         1|        17|   33| 8.1357|\n|         1|        17|  294|  6.819|\n+----------+----------+-----+-------+\nonly showing top 20 rows\n\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Row(article_id=1, channel_id=17, index=19, weights=68.1899)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "kewords_tfidf.count()\n",
    "kewords_tfidf.show()\n",
    "kewords_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "# 解析出词表中所有词的idf值\n",
    "keywords_list_with_idf = list(zip(cv_model.vocabulary, idf_model.idf.toArray()))\n",
    "# 重新组装数据格式[keyword, idf-weight, index]，比如，['this', 0.6061358035703155, 0]\n",
    "def append_index(data):\n",
    "    for index in range(len(data)):\n",
    "        data[index] = list(data[index]) # 将元组转为list，比如('this', 0.6061358035703155)\n",
    "        data[index].append(index)       # 加入单词的索引index\n",
    "        data[index][1] = float(data[index][1])  # 转换单词的idf权重值的格式\n",
    "append_index(keywords_list_with_idf)\n",
    "rdd = oa.spark.sparkContext.parallelize(keywords_list_with_idf)  # 创建rdd\n",
    "idf_keywords = rdd.toDF([\"keywords\", \"idf\", \"index\"])\n",
    "# 把生成的idf数据写入hive表中\n",
    "# idf_keywords.write.insertInto('idf_keywords_values')\n",
    "idf_keywords.createOrReplaceTempView(\"tmp_idf_keywords\")\n",
    "new_sql = \"\"\"\n",
    "    insert overwrite table idf_keywords_values\n",
    "    select *\n",
    "    from tmp_idf_keywords\n",
    "    \"\"\"\n",
    "oa.spark.sql(new_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1266"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "# 利用keywordsIndex = ktt.spark.sql(\"select keyword, index idx from idf_keywords_values\")中标，知道索引对应的词\n",
    "idf_keywords_values = oa.spark.sql(\"select keyword, index idx from idf_keywords_values\")\n",
    "idf_keywords_values.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "metadata": {},
     "execution_count": 46
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+----------+-----------+-------+\n|article_id|channel_id|    keyword|weights|\n+----------+----------+-----------+-------+\n|         1|        17|        div|68.1899|\n|         1|        17|      child|58.4677|\n|         1|        17|       组件|55.6381|\n|         1|        17|      props|52.8472|\n|         1|        17|forChildMsg|39.2092|\n|         1|        17|        msg|31.1828|\n|         1|        17|ownChildMsg|30.6855|\n|         1|        17|  childNode|30.6855|\n|         1|        17|   template| 27.276|\n|         1|        17|   rentNode|15.3427|\n|         1|        17|        Vue|15.3427|\n|         1|        17|       prop| 13.638|\n|         1|        17|       rent| 13.638|\n|         1|        17|     String| 13.638|\n|         1|        17|       数据|11.2996|\n|         1|        17| components|10.2285|\n|         1|        17|       模板| 8.5237|\n|         1|        17|       警告| 8.5237|\n|         1|        17|        for| 8.1357|\n|         1|        17|       type|  6.819|\n+----------+----------+-----------+-------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "keyword_str_tfidf = kewords_tfidf.join(idf_keywords_values, idf_keywords_values.idx==kewords_tfidf.index).select([\"article_id\", \"channel_id\", \"keyword\", \"weights\"])\n",
    "\n",
    "keyword_str_tfidf.count()\n",
    "keyword_str_tfidf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_tfidf(partition):\n",
    "    TOPK = 20\n",
    "    for row in partition:\n",
    "        # 找到索引与IDF值并进行排序\n",
    "        _dict = list(zip(row.idfFeatures.indices, row.idfFeatures.values))\n",
    "        _dict = sorted(_dict, key=lambda x: x[1], reverse=True)\n",
    "        result = _dict[:TOPK]\n",
    "        for word_index, tfidf in result:\n",
    "            yield row.article_id, row.channel_id, int(word_index), round(float(tfidf), 4)\n",
    "\n",
    "keywords_by_tfidf = tfidf_res.rdd.mapPartitions(sort_by_tfidf).toDF([\"article_id\", \"channel_id\", \"index\", \"weights\"])\n",
    "keywords_index = oa.spark.sql(\"select keyword, index idx from idf_keywords_values\")\n",
    "keywords_result = keywords_by_tfidf.join(keywords_index, keywords_index.idx == keywords_by_tfidf.index).select([\"article_id\", \"channel_id\", \"keyword\", \"weights\"])\n",
    "keywords_result.write.insertInto(\"tfidf_keywords_values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# texrank\n",
    "# 分词\n",
    "def textrank(partition):\n",
    "    import os\n",
    "\n",
    "    import jieba\n",
    "    import jieba.analyse\n",
    "    import jieba.posseg as pseg\n",
    "    import codecs\n",
    "\n",
    "    abspath = \"/opt/words\"\n",
    "\n",
    "    # 结巴加载用户词典\n",
    "    userDict_path = os.path.join(abspath, \"ITKeywords.txt\")\n",
    "    jieba.load_userdict(userDict_path)\n",
    "\n",
    "    # 停用词文本\n",
    "    stopwords_path = os.path.join(abspath, \"stopwords.txt\")\n",
    "\n",
    "    def get_stopwords_list():\n",
    "        \"\"\"返回stopwords列表\"\"\"\n",
    "        stopwords_list = [i.strip()\n",
    "                          for i in codecs.open(stopwords_path, encoding='utf-8').readlines()]\n",
    "        return stopwords_list\n",
    "\n",
    "    # 所有的停用词列表\n",
    "    stopwords_list = get_stopwords_list()\n",
    "\n",
    "    class TextRank(jieba.analyse.TextRank):\n",
    "        def __init__(self, window=20, word_min_len=2):\n",
    "            super(TextRank, self).__init__()\n",
    "            self.span = window  # 窗口大小\n",
    "            self.word_min_len = word_min_len  # 单词的最小长度\n",
    "            # 要保留的词性，根据jieba github ，具体参见https://github.com/baidu/lac\n",
    "            self.pos_filt = frozenset(\n",
    "                ('n', 'x', 'eng', 'f', 's', 't', 'nr', 'ns', 'nt', \"nw\", \"nz\", \"PER\", \"LOC\", \"ORG\"))\n",
    "\n",
    "        def pairfilter(self, wp):\n",
    "            \"\"\"过滤条件，返回True或者False\"\"\"\n",
    "\n",
    "            if wp.flag == \"eng\":\n",
    "                if len(wp.word) <= 2:\n",
    "                    return False\n",
    "\n",
    "            if wp.flag in self.pos_filt and len(wp.word.strip()) >= self.word_min_len \\\n",
    "                    and wp.word.lower() not in stopwords_list:\n",
    "                return True\n",
    "    # TextRank过滤窗口大小为5，单词最小为2\n",
    "    textrank_model = TextRank(window=5, word_min_len=2)\n",
    "    allowPOS = ('n', \"x\", 'eng', 'nr', 'ns', 'nt', \"nw\", \"nz\", \"c\")\n",
    "\n",
    "    for row in partition:\n",
    "        tags = textrank_model.textrank(row.sentence, topK=20, withWeight=True, allowPOS=allowPOS, withFlag=False)\n",
    "        for tag in tags:\n",
    "            yield row.article_id, row.channel_id, tag[0], tag[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "textrank_keywords_df = article_data.rdd.mapPartitions(textrank).toDF([\"article_id\", \"channel_id\", \"keyword\", \"textrank\"])\n",
    "\n",
    "textrank_keywords_df.write.insertInto(\"textrank_keywords_values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "metadata": {},
     "execution_count": 51
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+----------+-----------+-------------------+\n|article_id|channel_id|    keyword|           textrank|\n+----------+----------+-----------+-------------------+\n|         1|        17|       组件|                1.0|\n|         1|        17|      props| 0.5154370285370792|\n|         1|        17|        msg| 0.4702870805040915|\n|         1|        17|       数据|0.45582871346014814|\n|         1|        17|      child|0.31296871088663686|\n|         1|        17|     strong| 0.3089686862986876|\n|         1|        17|       code| 0.3032954542098871|\n|         1|        17|        Vue|0.24087919593391022|\n|         1|        17|         pa|0.22048638072881815|\n|         1|        17|         ul| 0.2018632319447092|\n|         1|        17|  childNode|0.19610401758526286|\n|         1|        17|     String|0.17134793062324802|\n|         1|        17|forChildMsg| 0.1668240799844303|\n|         1|        17|       defa| 0.1655549274585362|\n|         1|        17|        pre|0.15524657279047274|\n|         1|        17|  validator|0.15421576195324882|\n|         1|        17|       属性|0.15197896394191618|\n|         1|        17|       定义|0.14652996142104396|\n|         1|        17|   函数返回|0.14198051680758564|\n|         1|        17|       函数|0.14138761520330873|\n+----------+----------+-----------+-------------------+\nonly showing top 20 rows\n\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Row(article_id=1, channel_id=17, keyword='组件', textrank=1.0)"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "textrank_keywords_df.count()\n",
    "textrank_keywords_df.show()\n",
    "textrank_keywords_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文章画像 关键词与权重合并\n",
    "# textrank * idf\n",
    "idf_keywords_values = oa.spark.sql(\"select * from idf_keywords_values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1266"
      ]
     },
     "metadata": {},
     "execution_count": 54
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------+------------------+-----+\n|keyword|               idf|index|\n+-------+------------------+-----+\n|   this|0.6061358035703155|    0|\n|     pa|               0.0|    1|\n|   node|0.6061358035703155|    2|\n|   data|0.6061358035703155|    3|\n|   数据|0.4519851237430572|    4|\n|    let|0.7884573603642703|    5|\n|   keys|1.0116009116784799|    6|\n|    obj|1.0116009116784799|    7|\n|   组件|1.0116009116784799|    8|\n|    npm|0.7884573603642703|    9|\n|  child|1.2992829841302609|   10|\n|   节点|1.7047480922384253|   11|\n|    log|0.3184537311185346|   12|\n|   属性|1.0116009116784799|   13|\n|    key|0.7884573603642703|   14|\n|console|0.4519851237430572|   15|\n|  value|0.7884573603642703|   16|\n|    var|0.7884573603642703|   17|\n| return|0.4519851237430572|   18|\n|    div|1.7047480922384253|   19|\n+-------+------------------+-----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "idf_keywords_values.count()\n",
    "idf_keywords_values.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_res = textrank_keywords_df.join(idf_keywords_values, on=['keyword'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "metadata": {},
     "execution_count": 56
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------+----------+----------+-------------------+-------------------+-----+\n|    keyword|article_id|channel_id|           textrank|                idf|index|\n+-----------+----------+----------+-------------------+-------------------+-----+\n|       组件|         1|        17|                1.0| 1.0116009116784799|    8|\n|      props|         1|        17| 0.5154370285370792| 1.7047480922384253|   26|\n|        msg|         1|        17| 0.4702870805040915| 1.2992829841302609|   27|\n|       数据|         1|        17|0.45582871346014814| 0.4519851237430572|    4|\n|      child|         1|        17|0.31296871088663686| 1.2992829841302609|   10|\n|     strong|         1|        17| 0.3089686862986876|               null| null|\n|       code|         1|        17| 0.3032954542098871|               null| null|\n|        Vue|         1|        17|0.24087919593391022| 1.7047480922384253|  139|\n|         pa|         1|        17|0.22048638072881815|                0.0|    1|\n|         ul|         1|        17| 0.2018632319447092|0.20067069546215124|   31|\n|  childNode|         1|        17|0.19610401758526286| 1.7047480922384253|   58|\n|     String|         1|        17|0.17134793062324802| 1.7047480922384253|  175|\n|forChildMsg|         1|        17| 0.1668240799844303| 1.7047480922384253|   39|\n|       defa|         1|        17| 0.1655549274585362| 1.7047480922384253|  330|\n|        pre|         1|        17|0.15524657279047274|               null| null|\n|  validator|         1|        17|0.15421576195324882| 1.7047480922384253|  301|\n|       属性|         1|        17|0.15197896394191618| 1.0116009116784799|   13|\n|       定义|         1|        17|0.14652996142104396| 0.7884573603642703|   90|\n|   函数返回|         1|        17|0.14198051680758564| 1.7047480922384253|  508|\n|       函数|         1|        17|0.14138761520330873| 0.6061358035703155|   44|\n+-----------+----------+----------+-------------------+-------------------+-----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "keywords_res.count()\n",
    "keywords_res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "metadata": {},
     "execution_count": 59
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+----------+-----------+-------------------+\n|article_id|channel_id|    keyword|            weights|\n+----------+----------+-----------+-------------------+\n|         1|        17|       组件| 1.0116009116784799|\n|         1|        17|      props| 0.8786902910676285|\n|         1|        17|        msg| 0.6110360013552643|\n|         1|        17|       数据|0.20602779745892363|\n|         1|        17|      child| 0.4066349206201904|\n|         1|        17|     strong|               null|\n|         1|        17|       code|               null|\n|         1|        17|        Vue| 0.4106383497282593|\n|         1|        17|         pa|                0.0|\n|         1|        17|         ul|0.04050803514258234|\n|         1|        17|  childNode|0.33430794985876744|\n|         1|        17|     String| 0.2921050578389841|\n|         1|        17|forChildMsg|  0.284393032092888|\n|         1|        17|       defa|0.28222944674561046|\n|         1|        17|        pre|               null|\n|         1|        17|  validator|0.26289902598289605|\n|         1|        17|       属性| 0.1537420584795932|\n|         1|        17|       定义|0.11553262659631468|\n|         1|        17|   函数返回|0.24204101516275728|\n|         1|        17|       函数|0.08570009575614809|\n+----------+----------+-----------+-------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "keywords_weights = keywords_res.withColumn('weights', keywords_res.textrank * keywords_res.idf).select([\"article_id\", \"channel_id\", \"keyword\", \"weights\"])\n",
    "keywords_weights.count()\n",
    "keywords_weights.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Row(article_id=7, channel_id=17, keywords=['code', '以太坊', 'web3', '合约', 'pre', 'var', '交易', 'eth', 'config', '智能', 'oschina', 'affid', 'ethereum', 'github', 'https', 'href', '区块链', '内容', 'truffle', 'http'], weights=[0.7166252318348719, 0.6165939326860989, 0.594581360981357, 0.22097663204437684, 0.47769652324354406, 0.439316793855322, 0.23920844096338223, 0.3644739102690279, 0.35928887983850694, 0.3203133406779015, 0.18140689390402723, 0.17533670142413396, 0.2859854782648112, 0.09034120068041016, 0.2393229613380347, 0.1086271150745705])"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "keywords_weights.registerTempTable('temp')\n",
    "keywords_weights = oa.spark.sql(\"select article_id, min(channel_id) channel_id, collect_list(keyword) keywords, collect_list(weights) weights from temp group by article_id\")\n",
    "\n",
    "keywords_weights.count()\n",
    "keywords_weights.show()\n",
    "keywords_weights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并关键词和权重到字典\n",
    "def _func(row):\n",
    "    return row.article_id, row.channel_id, dict(zip(row.keywords, row.weights))\n",
    "\n",
    "article_kewords = keywords_weights.rdd.map(_func).toDF(['article_id', 'channel_id', 'keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "metadata": {},
     "execution_count": 67
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+----------+----------------------+\n|article_id|channel_id|              keywords|\n+----------+----------+----------------------+\n|         7|        17|  [github -> 0.0903...|\n|         6|        17|  [jpg -> 0.4829933...|\n|         9|        17|  [loadStyle -> 0.0...|\n|         5|        17|  [r2 -> 0.07908227...|\n|         1|        17|  [msg -> 0.6110360...|\n|        10|        17|  [nofollow -> 0.83...|\n|         3|        17|  [jpg -> 0.4052402...|\n|         8|        17|  [app -> 0.4392507...|\n|         2|        17|[属性 -> 1.00270783...|\n|         4|        17|  [jpg -> 0.9989083...|\n+----------+----------+----------------------+\n\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Row(article_id=7, channel_id=17, keywords={'github': 0.09034120068041016, 'pre': 0.47769652324354406, 'code': 0.7166252318348719, '交易': 0.23920844096338223, 'var': 0.439316793855322, 'oschina': 0.18140689390402723, 'web3': 0.594581360981357, '智能': 0.3203133406779015, 'ethereum': 0.2859854782648112, '合约': 0.22097663204437684, '以太坊': 0.6165939326860989, 'eth': 0.3644739102690279, 'affid': 0.17533670142413396, 'href': 0.1086271150745705, 'https': 0.2393229613380347, 'config': 0.35928887983850694})"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "article_kewords.count()\n",
    "article_kewords.show()\n",
    "article_kewords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算tfidf与texrank共同词作为主题词\n",
    "topic_sql = \"select t.article_id article_id2, collect_set(t.keyword) topics from tfidf_keywords_values t inner join textrank_keywords_values r where t.keyword=r.keyword group by article_id2\"\n",
    "article_topics = oa.spark.sql(topic_sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "metadata": {},
     "execution_count": 69
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------+--------------------------+\n|article_id2|                    topics|\n+-----------+--------------------------+\n|          7|[交易, 内容, eth, 合约,...|\n|          6|      [vue, https, &#, ...|\n|          9|  [item, 数据驱动, goLi...|\n|          5|      [r2, obj, console...|\n|          1|    [props, child, 组件...|\n|         10|   [WebSocket, 源码, 域...|\n|          3|   [Array, obj, 浅拷贝,...|\n|          8|    [模式, mode, optimi...|\n|          2|    [match, DOM, 节点, ...|\n|          4| [bin, 数据库, 项目, wi...|\n+-----------+--------------------------+\n\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Row(article_id2=7, topics=['交易', '内容', 'eth', '合约', 'config', 'web3', 'var', '区块链', 'truffle', '智能', '以太坊'])"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "article_topics.count()\n",
    "article_topics.show()\n",
    "article_topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 关键词与主题词结果合并，得到文章的最终完整画像\n",
    "article_profile = article_kewords.join(article_topics, article_kewords.article_id==article_topics.article_id2).select([\"article_id\", \"channel_id\", \"keywords\", \"topics\"])\n",
    "\n",
    "# article_profile.write.insertInto(\"article_profile\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "metadata": {},
     "execution_count": 71
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+----------+----------------------+--------------------------+\n|article_id|channel_id|              keywords|                    topics|\n+----------+----------+----------------------+--------------------------+\n|         7|        17|  [github -> 0.0903...|[交易, 内容, eth, 合约,...|\n|         6|        17|  [jpg -> 0.4829933...|      [vue, https, &#, ...|\n|         9|        17|  [loadStyle -> 0.0...|  [item, 数据驱动, goLi...|\n|         5|        17|  [r2 -> 0.07908227...|      [r2, obj, console...|\n|         1|        17|  [msg -> 0.6110360...|    [props, child, 组件...|\n|        10|        17|  [nofollow -> 0.83...|   [WebSocket, 源码, 域...|\n|         3|        17|  [jpg -> 0.4052402...|   [Array, obj, 浅拷贝,...|\n|         8|        17|  [app -> 0.4392507...|    [模式, mode, optimi...|\n|         2|        17|[属性 -> 1.00270783...|    [match, DOM, 节点, ...|\n|         4|        17|  [jpg -> 0.9989083...| [bin, 数据库, 项目, wi...|\n+----------+----------+----------------------+--------------------------+\n\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Row(article_id=7, channel_id=17, keywords={'github': 0.09034120068041016, 'pre': 0.47769652324354406, 'code': 0.7166252318348719, '交易': 0.23920844096338223, 'var': 0.439316793855322, 'oschina': 0.18140689390402723, 'web3': 0.594581360981357, '智能': 0.3203133406779015, 'ethereum': 0.2859854782648112, '合约': 0.22097663204437684, '以太坊': 0.6165939326860989, 'eth': 0.3644739102690279, 'affid': 0.17533670142413396, 'href': 0.1086271150745705, 'https': 0.2393229613380347, 'config': 0.35928887983850694}, topics=['交易', '内容', 'eth', '合约', 'config', 'web3', 'var', '区块链', 'truffle', '智能', '以太坊'])"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "article_profile.count()\n",
    "article_profile.show()\n",
    "article_profile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}